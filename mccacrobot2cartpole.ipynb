{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from actorcritic import Network  # Replace with the actual import for your Network class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a model\n",
    "def load_model(model_path, input_size, output_size, hidden_sizes, is_policy):\n",
    "    model = Network(input_size, output_size, hidden_sizes, is_policy)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model\n",
    "\n",
    "# Function to freeze a network\n",
    "def freeze_network(network):\n",
    "    for param in network.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Network class to accept additional inputs from source networks\n",
    "class ProgressiveNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_sizes, source_networks=[], is_policy=True):\n",
    "        super(ProgressiveNetwork, self).__init__()\n",
    "        self.is_policy = is_policy\n",
    "        self.source_networks = source_networks\n",
    "        # Adjust the input size to include source networks' top hidden layer outputs\n",
    "        adjusted_input_size = input_size + sum([hidden_sizes[-1] for _ in source_networks])  # Assumes the last hidden layer size is indicative\n",
    "\n",
    "        # Building the layers\n",
    "        layers = [nn.Linear(adjusted_input_size, hidden_sizes[0]), nn.ReLU()]\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        if is_policy:\n",
    "            self.network.add_module(\"softmax\", nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Collect outputs from source network(s)\n",
    "        source_outputs = [source.network[:-1](x).detach() for source in self.source_networks]  # Assumes source output is from the second last layer\n",
    "        if source_outputs:\n",
    "            x = torch.cat([x] + source_outputs, dim=1)\n",
    "        \n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of setting up and using the Progressive Network\n",
    "# Assuming the input_size, output_size, and hidden_sizes are defined elsewhere\n",
    "source_networks = [load_model('Acrobot-v1_policy_network.pth', acrobot_input_size, acrobot_output_size, [64, 128, 64], True),\n",
    "                   load_model('MountainCarContinuous-v0_policy_network.pth', mcc_input_size, mcc_output_size, [64, 128, 64], True)]\n",
    "\n",
    "# Freeze the source networks\n",
    "for net in source_networks:\n",
    "    freeze_network(net)\n",
    "\n",
    "# Setup Progressive Network for CartPole (or another target task)\n",
    "# You need to define cartpole_input_size, cartpole_output_size, and whether it's a policy or value network accordingly\n",
    "target_network = ProgressiveNetwork(cartpole_input_size, cartpole_output_size, [64, 128, 64], source_networks, is_policy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logdeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
